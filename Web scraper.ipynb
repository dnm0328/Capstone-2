{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offensive Web Scrape --> CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.footballdb.com/stats/teamstat.html?lg=NFL&yr=2009&type=reg&cat=T&group=O&conf=',\n",
       " 'https://www.footballdb.com/stats/teamstat.html?lg=NFL&yr=2010&type=reg&cat=T&group=O&conf=',\n",
       " 'https://www.footballdb.com/stats/teamstat.html?lg=NFL&yr=2011&type=reg&cat=T&group=O&conf=',\n",
       " 'https://www.footballdb.com/stats/teamstat.html?lg=NFL&yr=2012&type=reg&cat=T&group=O&conf=',\n",
       " 'https://www.footballdb.com/stats/teamstat.html?lg=NFL&yr=2013&type=reg&cat=T&group=O&conf=',\n",
       " 'https://www.footballdb.com/stats/teamstat.html?lg=NFL&yr=2014&type=reg&cat=T&group=O&conf=',\n",
       " 'https://www.footballdb.com/stats/teamstat.html?lg=NFL&yr=2015&type=reg&cat=T&group=O&conf=',\n",
       " 'https://www.footballdb.com/stats/teamstat.html?lg=NFL&yr=2016&type=reg&cat=T&group=O&conf=',\n",
       " 'https://www.footballdb.com/stats/teamstat.html?lg=NFL&yr=2017&type=reg&cat=T&group=O&conf=',\n",
       " 'https://www.footballdb.com/stats/teamstat.html?lg=NFL&yr=2018&type=reg&cat=T&group=O&conf=',\n",
       " 'https://www.footballdb.com/stats/teamstat.html?lg=NFL&yr=2019&type=reg&cat=T&group=O&conf=']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_list = []\n",
    "for i in list(range(2009, 2020)):\n",
    "    string = 'https://www.footballdb.com/stats/teamstat.html?lg=NFL&yr={}&type=reg&cat=T&group=O&conf='\n",
    "    string = string.format(i)\n",
    "    url_list.append(string)\n",
    "url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.1.1 Safari/605.1.15\",\n",
    "        \"Host\": \"www.footballdb.com\",\n",
    "        \"Referer\": \"https://www.footballdb.com/stats/teamstat.html?group=O&cat=T\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Make_Save_Offensive_DB(url_list, headers):\n",
    "    '''\n",
    "    This function takes a list of URLs, along with \n",
    "    proper header information, scrapes each of the\n",
    "    tables within the URl and turn HTML data into a \n",
    "    pandas DF. \n",
    "    ------------------------------------\n",
    "    PARAMETERS: List of URL addresses for scrape/ \n",
    "    Dictionary of authorized header parameters \n",
    "    ------------------------------------\n",
    "    \n",
    "    '''\n",
    "    year = 2009\n",
    "    for url in url_list:\n",
    "        columns = {}\n",
    "        r = requests.get(url, headers=headers)\n",
    "#         print(r.status_code)\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        col_names = soup.find_all('th')\n",
    "        row_names = soup.find_all('tr')\n",
    "        for col in col_names:\n",
    "            columns[col.text] = None\n",
    "            dict_data = []\n",
    "            keys = list(columns.keys())\n",
    "        for i, row in enumerate(row_names):\n",
    "            if i > 0:\n",
    "                new_row = copy.copy(columns)\n",
    "                entries = row.find_all('td')\n",
    "                for j, entry in enumerate(entries):\n",
    "                    new_row[keys[j]] = entry.text\n",
    "                dict_data.append(new_row)\n",
    "        df = pd.DataFrame(dict_data)\n",
    "        df['year'] = year\n",
    "        df.to_csv(f'data/{year}.csv', index=False)\n",
    "        year += 1\n",
    "        time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Make_Save_Offensive_DB(url_list, headers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
